# Creative Research Report — copy to .env and fill in
# For minimal testing: copy .env.minimal and set only OPENAI_API_KEY.

# Required (only credential needed to test pipeline)
OPENAI_API_KEY=sk-...

# Product URL for Pipeline v2 (run_pipeline_v2.py uses this)
PRODUCT_URL=https://www.flipkart.com/your-product/p/...

# --- Scraping ---
# Apify (multi-platform: TikTok, Instagram, Amazon) — get token at apify.com
APIFY_API_TOKEN=apify_api_...
# SKIP_APIFY=1  # Set to skip Apify if client crashes (e.g. on some macOS)

# YouTube Data API v3 (free quota) — enable at console.cloud.google.com
YOUTUBE_API_KEY=...
# or
GOOGLE_API_KEY=...

# Reddit: not needed — we use public JSON API (reddit.com/r/subreddit/hot.json) with User-Agent: creative-research-bot/1.0

# Tavily (competitor analysis) — get key at tavily.com; 1000 free credits/month
TAVILY_API_KEY=tvly-...

# --- Video analysis (Pipeline v2) ---
# Gemini for video analysis (hooks, CTAs, format) — get key at ai.google.dev
GEMINI_API_KEY=...
# or reuse GOOGLE_API_KEY if same project
# GEMINI_MODEL=gemini-2.0-flash  # Override model (default: gemini-2.0-flash). Use gemini-1.5-flash if 404.
# GEMINI_BATCH_DELAY=3  # Seconds between video analyses (avoids RPM limits). See ai.google.dev/gemini-api/docs/rate-limits
# SKIP_GEMINI_ANALYSIS=1  # Skip video analysis when quota exhausted (pipeline continues without Gemini)

# --- Storage (optional) ---
# Airtable — api key at airtable.com/account, base ID from base URL
AIRTABLE_API_KEY=...
AIRTABLE_BASE_ID=...

# --- MCP (optional) ---
# CREATIVE_RESEARCH_MCP_HTTP=1   # set to run MCP server over HTTP
